{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed files exist. Loading them...\n",
      "Finish loading\n",
      "Total relation fact: 1700\n",
      "Pre-processed files exist. Loading them...\n",
      "Finish loading\n",
      "Total relation fact: 617\n",
      "Start training...\n",
      "Calculating weights_table...\n",
      "Finish calculating\n",
      "  name = %s, shape = %s word_embedding/word_embedding:0 (62073, 50)\n",
      "  name = %s, shape = %s word_embedding/unk_word_embedding:0 (1, 50)\n",
      "  name = %s, shape = %s pos_embedding/real_pos1_embedding:0 (240, 5)\n",
      "  name = %s, shape = %s pos_embedding/real_pos2_embedding:0 (240, 5)\n",
      "  name = %s, shape = %s pcnn/conv1d/kernel:0 (3, 60, 230)\n",
      "  name = %s, shape = %s pcnn/conv1d/bias:0 (230,)\n",
      "  name = %s, shape = %s attention/logit/relation_matrix:0 (4, 690)\n",
      "  name = %s, shape = %s attention/logit/bias:0 (4,)\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/nyt_pcnn_att\n",
      "pretrain_model is loaded...\n",
      "###### Epoch 0 ######\n",
      "epoch 0 step 0 time 23.66 | loss: 0.004573, not NA accuracy: 1.000000, accuracy: 1.000000\n",
      "epoch 0 step 1 time 7.01 | loss: 0.008204, not NA accuracy: 1.000000, accuracy: 1.000000\n",
      "epoch 0 step 2 time 15.07 | loss: 0.013864, not NA accuracy: 0.984375, accuracy: 0.997917\n",
      "epoch 0 step 3 time 8.69 | loss: 0.001686, not NA accuracy: 0.987342, accuracy: 0.998437\n",
      "epoch 0 step 4 time 7.75 | loss: 0.002841, not NA accuracy: 0.990476, accuracy: 0.998750\n",
      "epoch 0 step 5 time 7.47 | loss: 0.006889, not NA accuracy: 0.984375, accuracy: 0.997917\n",
      "epoch 0 step 6 time 7.71 | loss: 0.003954, not NA accuracy: 0.986486, accuracy: 0.998214\n",
      "epoch 0 step 7 time 9.43 | loss: 0.002588, not NA accuracy: 0.988304, accuracy: 0.998437\n",
      "epoch 0 step 8 time 13.83 | loss: 0.003589, not NA accuracy: 0.989950, accuracy: 0.998611\n",
      "epoch 0 step 9 time 8.45 | loss: 0.002943, not NA accuracy: 0.991031, accuracy: 0.998750\n",
      "epoch 0 step 10 time 7.31 | loss: 0.005649, not NA accuracy: 0.987854, accuracy: 0.998295\n",
      "epoch 0 step 11 time 11.55 | loss: 0.006959, not NA accuracy: 0.984962, accuracy: 0.997917\n",
      "epoch 0 step 12 time 9.21 | loss: 0.017337, not NA accuracy: 0.979094, accuracy: 0.997115\n",
      "epoch 0 step 13 time 7.94 | loss: 0.003151, not NA accuracy: 0.980707, accuracy: 0.997321\n",
      "epoch 0 step 14 time 7.92 | loss: 0.002260, not NA accuracy: 0.982196, accuracy: 0.997500\n",
      "epoch 0 step 15 time 9.53 | loss: 0.001853, not NA accuracy: 0.983380, accuracy: 0.997656\n",
      "epoch 0 step 16 time 6.10 | loss: 0.005846, not NA accuracy: 0.981579, accuracy: 0.997426\n",
      "epoch 0 step 17 time 8.80 | loss: 0.002615, not NA accuracy: 0.982673, accuracy: 0.997569\n",
      "epoch 0 step 18 time 10.20 | loss: 0.005488, not NA accuracy: 0.983945, accuracy: 0.997697\n",
      "epoch 0 step 19 time 7.07 | loss: 0.010054, not NA accuracy: 0.982721, accuracy: 0.997500\n",
      "epoch 0 step 20 time 14.30 | loss: 0.002996, not NA accuracy: 0.983539, accuracy: 0.997619\n",
      "epoch 0 step 21 time 8.81 | loss: 0.020552, not NA accuracy: 0.978641, accuracy: 0.996875\n",
      "epoch 0 step 22 time 12.85 | loss: 0.002804, not NA accuracy: 0.979592, accuracy: 0.997011\n",
      "epoch 0 step 23 time 8.69 | loss: 0.017749, not NA accuracy: 0.978947, accuracy: 0.996615\n",
      "epoch 0 step 24 time 6.13 | loss: 0.005494, not NA accuracy: 0.977929, accuracy: 0.996500\n",
      "epoch 0 step 25 time 8.79 | loss: 0.013763, not NA accuracy: 0.977011, accuracy: 0.996394\n",
      "epoch 0 step 26 time 10.07 | loss: 0.018247, not NA accuracy: 0.974922, accuracy: 0.996065\n",
      "epoch 0 step 27 time 6.10 | loss: 0.000386, not NA accuracy: 0.975721, accuracy: 0.996205\n",
      "epoch 0 step 28 time 9.23 | loss: 0.004671, not NA accuracy: 0.976505, accuracy: 0.996336\n",
      "epoch 0 step 29 time 7.86 | loss: 0.003195, not NA accuracy: 0.977337, accuracy: 0.996458\n",
      "epoch 0 step 30 time 8.67 | loss: 0.005130, not NA accuracy: 0.976519, accuracy: 0.996371\n",
      "epoch 0 step 31 time 8.25 | loss: 0.003437, not NA accuracy: 0.977454, accuracy: 0.996484\n",
      "epoch 0 step 32 time 10.41 | loss: 0.001161, not NA accuracy: 0.978121, accuracy: 0.996591\n",
      "epoch 0 step 33 time 8.05 | loss: 0.001785, not NA accuracy: 0.978803, accuracy: 0.996691\n",
      "epoch 0 step 34 time 14.30 | loss: 0.004212, not NA accuracy: 0.979567, accuracy: 0.996786\n",
      "epoch 0 step 35 time 7.83 | loss: 0.003974, not NA accuracy: 0.980278, accuracy: 0.996875\n",
      "epoch 0 step 36 time 7.27 | loss: 0.002889, not NA accuracy: 0.980616, accuracy: 0.996959\n",
      "epoch 0 step 37 time 17.49 | loss: 0.009370, not NA accuracy: 0.980022, accuracy: 0.996875\n",
      "epoch 0 step 38 time 10.90 | loss: 0.001106, not NA accuracy: 0.980435, accuracy: 0.996955\n",
      "epoch 0 step 39 time 7.76 | loss: 0.015584, not NA accuracy: 0.979787, accuracy: 0.996875\n",
      "epoch 0 step 40 time 8.65 | loss: 0.009663, not NA accuracy: 0.979339, accuracy: 0.996799\n",
      "epoch 0 step 41 time 7.69 | loss: 0.003383, not NA accuracy: 0.979839, accuracy: 0.996875\n",
      "epoch 0 step 42 time 13.16 | loss: 0.004546, not NA accuracy: 0.979432, accuracy: 0.996802\n",
      "epoch 0 step 43 time 8.11 | loss: 0.015830, not NA accuracy: 0.978866, accuracy: 0.996733\n",
      "epoch 0 step 44 time 10.76 | loss: 0.012270, not NA accuracy: 0.977591, accuracy: 0.996528\n",
      "epoch 0 step 45 time 5.82 | loss: 0.010987, not NA accuracy: 0.977106, accuracy: 0.996467\n",
      "epoch 0 step 46 time 7.18 | loss: 0.008052, not NA accuracy: 0.976534, accuracy: 0.996410\n",
      "epoch 0 step 47 time 8.01 | loss: 0.003193, not NA accuracy: 0.977093, accuracy: 0.996484\n",
      "epoch 0 step 48 time 12.34 | loss: 0.005356, not NA accuracy: 0.977778, accuracy: 0.996556\n",
      "epoch 0 step 49 time 7.26 | loss: 0.014527, not NA accuracy: 0.977387, accuracy: 0.996500\n",
      "epoch 0 step 50 time 6.92 | loss: 0.007342, not NA accuracy: 0.977143, accuracy: 0.996446\n",
      "epoch 0 step 51 time 7.67 | loss: 0.007812, not NA accuracy: 0.977600, accuracy: 0.996514\n",
      "epoch 0 step 52 time 5.87 | loss: 0.006681, not NA accuracy: 0.977183, accuracy: 0.996462\n",
      "epoch 0 step 53 time 10.97 | loss: 0.004388, not NA accuracy: 0.976852, accuracy: 0.996412\n",
      "epoch 0 step 54 time 9.36 | loss: 0.006545, not NA accuracy: 0.976497, accuracy: 0.996364\n",
      "epoch 0 step 55 time 16.96 | loss: 0.015817, not NA accuracy: 0.975483, accuracy: 0.996205\n",
      "epoch 0 step 56 time 7.64 | loss: 0.036126, not NA accuracy: 0.975219, accuracy: 0.996162\n",
      "epoch 0 step 57 time 6.32 | loss: 0.003246, not NA accuracy: 0.975610, accuracy: 0.996228\n",
      "epoch 0 step 58 time 6.13 | loss: 0.015624, not NA accuracy: 0.974630, accuracy: 0.996081\n",
      "epoch 0 step 59 time 10.19 | loss: 0.014288, not NA accuracy: 0.974323, accuracy: 0.996042\n",
      "epoch 0 step 60 time 7.10 | loss: 0.000111, not NA accuracy: 0.974658, accuracy: 0.996107\n",
      "epoch 0 step 61 time 8.36 | loss: 0.001005, not NA accuracy: 0.975118, accuracy: 0.996169\n",
      "epoch 0 step 62 time 6.81 | loss: 0.007054, not NA accuracy: 0.974784, accuracy: 0.996131\n",
      "epoch 0 step 63 time 8.44 | loss: 0.006743, not NA accuracy: 0.975228, accuracy: 0.996191\n",
      "epoch 0 step 64 time 8.09 | loss: 0.000610, not NA accuracy: 0.975657, accuracy: 0.996250\n",
      "epoch 0 step 65 time 7.19 | loss: 0.003318, not NA accuracy: 0.976086, accuracy: 0.996307\n",
      "epoch 0 step 66 time 9.56 | loss: 0.010191, not NA accuracy: 0.976427, accuracy: 0.996362\n",
      "epoch 0 step 67 time 11.72 | loss: 0.002988, not NA accuracy: 0.976701, accuracy: 0.996415\n",
      "epoch 0 step 68 time 9.66 | loss: 0.017425, not NA accuracy: 0.976421, accuracy: 0.996377\n",
      "epoch 0 step 69 time 15.26 | loss: 0.006175, not NA accuracy: 0.976148, accuracy: 0.996339\n",
      "epoch 0 step 70 time 5.50 | loss: 0.157783, not NA accuracy: 0.976471, accuracy: 0.996391\n",
      "\n",
      "Average iteration time: 9.340441\n",
      "Testing...\n",
      "Calculating weights_table...\n",
      "Finish calculating\n",
      "[TEST] step 13 | not NA accuracy: 0.838235, accuracy: 0.955804\n",
      "[TEST] auc: 0.8989572410117252\n",
      "Finish testing\n",
      "Best model, storing...\n",
      "INFO:tensorflow:checkpoint\\nyt_pcnn_att is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Finish storing\n",
      "###### Epoch 1 ######\n",
      "epoch 1 step 0 time 9.18 | loss: 0.008956, not NA accuracy: 0.961538, accuracy: 0.993750\n",
      "epoch 1 step 1 time 10.21 | loss: 0.019360, not NA accuracy: 0.960000, accuracy: 0.993750\n",
      "epoch 1 step 2 time 7.67 | loss: 0.007436, not NA accuracy: 0.960000, accuracy: 0.993750\n",
      "epoch 1 step 3 time 11.01 | loss: 0.006295, not NA accuracy: 0.969697, accuracy: 0.995313\n",
      "epoch 1 step 4 time 11.00 | loss: 0.006120, not NA accuracy: 0.966667, accuracy: 0.995000\n",
      "epoch 1 step 5 time 10.52 | loss: 0.003725, not NA accuracy: 0.974026, accuracy: 0.995833\n",
      "epoch 1 step 6 time 6.68 | loss: 0.002111, not NA accuracy: 0.977401, accuracy: 0.996429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 step 7 time 10.16 | loss: 0.002939, not NA accuracy: 0.979798, accuracy: 0.996875\n",
      "epoch 1 step 8 time 8.23 | loss: 0.004934, not NA accuracy: 0.981818, accuracy: 0.997222\n",
      "epoch 1 step 9 time 5.77 | loss: 0.001204, not NA accuracy: 0.983264, accuracy: 0.997500\n",
      "epoch 1 step 10 time 12.44 | loss: 0.009663, not NA accuracy: 0.980392, accuracy: 0.997159\n",
      "epoch 1 step 11 time 8.22 | loss: 0.001441, not NA accuracy: 0.982079, accuracy: 0.997396\n",
      "epoch 1 step 12 time 15.39 | loss: 0.000289, not NA accuracy: 0.983444, accuracy: 0.997596\n"
     ]
    }
   ],
   "source": [
    "import nrekit\n",
    "import nrekit.data_loader\n",
    "import nrekit.framework\n",
    "# import nrekit.rl\n",
    "import nrekit.network.embedding\n",
    "import nrekit.network.encoder\n",
    "import nrekit.network.selector\n",
    "import nrekit.network.classifier\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "\n",
    "dataset_name = 'nyt'\n",
    "\n",
    "dataset_dir = os.path.join('./data', dataset_name)\n",
    "if not os.path.isdir(dataset_dir):\n",
    "    raise Exception(\"[ERROR] Dataset dir %s doesn't exist!\" % (dataset_dir))\n",
    "\n",
    "\n",
    "# The first 3 parameters are train / test data file name, word embedding file name and relation-id mapping file name respectively.\n",
    "train_loader = nrekit.data_loader.json_file_data_loader(os.path.join(dataset_dir, 'train.json'), \n",
    "                                                        os.path.join(dataset_dir, 'word_vec.json'),\n",
    "                                                        os.path.join(dataset_dir, 'rel2id.json'), \n",
    "                                                        mode=nrekit.data_loader.json_file_data_loader.MODE_RELFACT_BAG,\n",
    "                                                        shuffle=True)\n",
    "test_loader = nrekit.data_loader.json_file_data_loader(os.path.join(dataset_dir, 'test.json'), \n",
    "                                                       os.path.join(dataset_dir, 'word_vec.json'),\n",
    "                                                       os.path.join(dataset_dir, 'rel2id.json'), \n",
    "                                                       mode=nrekit.data_loader.json_file_data_loader.MODE_ENTPAIR_BAG,\n",
    "                                                       shuffle=False)\n",
    "\n",
    "framework = nrekit.framework.re_framework(train_loader, test_loader)\n",
    "\n",
    "class model(nrekit.framework.re_model):\n",
    "    encoder = \"pcnn\"\n",
    "    selector = \"att\"\n",
    "\n",
    "    def __init__(self, train_data_loader, batch_size, max_length=120):\n",
    "        nrekit.framework.re_model.__init__(self, train_data_loader, batch_size, max_length=max_length)\n",
    "        self.mask = tf.placeholder(dtype=tf.int32, shape=[None, max_length], name=\"mask\")\n",
    "        \n",
    "        # Embedding\n",
    "        x = nrekit.network.embedding.word_position_embedding(self.word, self.word_vec_mat, self.pos1, self.pos2)\n",
    "\n",
    "        # Encoder\n",
    "        if model.encoder == \"pcnn\":\n",
    "            x_train = nrekit.network.encoder.pcnn(x, self.mask, keep_prob=0.5)\n",
    "            x_test = nrekit.network.encoder.pcnn(x, self.mask, keep_prob=1.0)\n",
    "        elif model.encoder == \"cnn\":\n",
    "            x_train = nrekit.network.encoder.cnn(x, keep_prob=0.5)\n",
    "            x_test = nrekit.network.encoder.cnn(x, keep_prob=1.0)\n",
    "        elif model.encoder == \"rnn\":\n",
    "            x_train = nrekit.network.encoder.rnn(x, self.length, keep_prob=0.5)\n",
    "            x_test = nrekit.network.encoder.rnn(x, self.length, keep_prob=1.0)\n",
    "        elif model.encoder == \"birnn\":\n",
    "            x_train = nrekit.network.encoder.birnn(x, self.length, keep_prob=0.5)\n",
    "            x_test = nrekit.network.encoder.birnn(x, self.length, keep_prob=1.0)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # Selector\n",
    "        if model.selector == \"att\":\n",
    "            self._train_logit, train_repre = nrekit.network.selector.bag_attention(x_train, self.scope, self.ins_label, self.rel_tot, True, keep_prob=0.5)\n",
    "            self._test_logit, test_repre = nrekit.network.selector.bag_attention(x_test, self.scope, self.ins_label, self.rel_tot, False, keep_prob=1.0)\n",
    "        elif model.selector == \"ave\":\n",
    "            self._train_logit, train_repre = nrekit.network.selector.bag_average(x_train, self.scope, self.rel_tot, keep_prob=0.5)\n",
    "            self._test_logit, test_repre = nrekit.network.selector.bag_average(x_test, self.scope, self.rel_tot, keep_prob=1.0)\n",
    "            self._test_logit = tf.nn.softmax(self._test_logit)\n",
    "        elif model.selector == \"one\":\n",
    "            self._train_logit, train_repre = nrekit.network.selector.bag_one(x_train, self.scope, self.label, self.rel_tot, True, keep_prob=0.5)\n",
    "            self._test_logit, test_repre = nrekit.network.selector.bag_one(x_test, self.scope, self.label, self.rel_tot, False, keep_prob=1.0)\n",
    "            self._test_logit = tf.nn.softmax(self._test_logit)\n",
    "        elif model.selector == \"cross_max\":\n",
    "            self._train_logit, train_repre = nrekit.network.selector.bag_cross_max(x_train, self.scope, self.rel_tot, keep_prob=0.5)\n",
    "            self._test_logit, test_repre = nrekit.network.selector.bag_cross_max(x_test, self.scope, self.rel_tot, keep_prob=1.0)\n",
    "            self._test_logit = tf.nn.softmax(self._test_logit)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        # Classifier\n",
    "        self._loss = nrekit.network.classifier.softmax_cross_entropy(self._train_logit, self.label, self.rel_tot, weights_table=self.get_weights())\n",
    " \n",
    "    def loss(self):\n",
    "        return self._loss\n",
    "\n",
    "    def train_logit(self):\n",
    "        return self._train_logit\n",
    "\n",
    "    def test_logit(self):\n",
    "        return self._test_logit\n",
    "\n",
    "    def get_weights(self):\n",
    "        with tf.variable_scope(\"weights_table\", reuse=tf.AUTO_REUSE):\n",
    "            print(\"Calculating weights_table...\")\n",
    "            _weights_table = np.zeros((self.rel_tot), dtype=np.float32)\n",
    "            for i in range(len(self.train_data_loader.data_rel)):\n",
    "                _weights_table[self.train_data_loader.data_rel[i]] += 1.0 \n",
    "            _weights_table = 1 / (_weights_table ** 0.05)\n",
    "            weights_table = tf.get_variable(name='weights_table', dtype=tf.float32, trainable=False, initializer=_weights_table)\n",
    "            print(\"Finish calculating\")\n",
    "        return weights_table\n",
    "\n",
    "ckpt = tf.train.latest_checkpoint('./checkpoint/')\n",
    "framework.train(model, model_name=dataset_name + \"_\" + model.encoder + \"_\" + model.selector, max_epoch=60, ckpt_dir=\"checkpoint\", gpu_nums=1,pretrain_model=ckpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating weights_table...\n",
      "Finish calculating\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/nyt_pcnn_att\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "model = model(framework.train_data_loader, 1)\n",
    "\n",
    "ckpt=\"./checkpoint/\" + dataset_name + \"_\" + model.encoder + \"_\" + model.selector\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\leo\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.888 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "郡县因为他鳏穷，给他每天五升粮食，食物不足，以乞食为生，乞讨不要多。\n",
      "head: 粮食 tail: 食物\n",
      "relation: subclass of\n"
     ]
    }
   ],
   "source": [
    "s = \"郡县因为他鳏穷，给他每天五升粮食，食物不足，以乞食为生，乞讨不要多。\"\n",
    "\n",
    "head = \"粮食\"\n",
    "tail = \"食物\"\n",
    "\n",
    "word2id = {0: 'NA', 1: 'instance of', 2: 'subclass of', 3: 'parent taxon'}\n",
    "\n",
    "from evaluate_input import evaluate_line\n",
    "dic = evaluate_line(s,head,tail)\n",
    "\n",
    "predict_label =(framework.one_step(sess, model, dic, [model.test_logit()])[0]).argmax(-1)\n",
    "print(s)\n",
    "print(\"head:\", head, \"tail:\", tail)\n",
    "print(\"relation:\",word2id[int(predict_label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
